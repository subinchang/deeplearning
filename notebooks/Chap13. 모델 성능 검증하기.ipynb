{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16044823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f85a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sonar.csv', header=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "문제1] sonar 데이터프레임을 이용하여 훈련 데이터를 분리하는 코드를 작성하세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf38a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 포함되어 있으니까 label encoding / one hot encoding / 둘다?\n",
    "# label encoding 당연히 필요, one hot은 다중분류에서만 사용.\n",
    "# 지금은 암석 or 돌멩이 판단 -> 이진 분류, one hot 수행하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 추출 완료\n",
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "print(type(dataset), dataset.shape, dataset.dtype)\n",
    "print(type(X), X.shape, X.dtype)\n",
    "print(type(Y), Y.shape, Y.dtype)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43932f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "문제2] sonar 데이터 셋을 이용하여 모델을 생성하고 학습을 수행하는 코드를 작성하세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계속 1.00 나오면 과적합을 의심해봐야 함\n",
    "# 학습 데이터에만 너무 최적화되어 있어 새로운 데이터 들어오면 정확도 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = (10, 11, 12, 13)\n",
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tpl():\n",
    "    return(14, 15, 16, 17)\n",
    "\n",
    "a, b, c, d = return_tpl()\n",
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set으로 학습 수행\n",
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "seed=1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ab424",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model.evaluate(X_train, Y_train, verbose=0)\n",
    "result2 = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# 손실도, 정확도\n",
    "\n",
    "print('[학습 모델 평가] loss: %.4f, accuracy: %.4f' % (result1[0], result1[1]))\n",
    "print('[테스트 모델 평가] loss: %.4f, accuracy: %.4f' % (result2[0], result2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "문제] 피마 인디언 데이터 셋을 사용하여 학습 셋과 테스트 셋을 분리하여 평가하고 그 결과를 보이는 코드를 작성하세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pima-indians-diabetes.csv', names=['pregnant', 'plasma', 'pressure',\n",
    "                'thickness', 'insulin', 'bmi', 'pedigree', 'age', 'class'])\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:8]\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=8, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=500, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11953c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model.evaluate(X_train, Y_train, verbose=0)\n",
    "result2 = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# 손실도, 정확도\n",
    "\n",
    "print('[학습 모델 평가] loss: %.4f, accuracy: %.4f' % (result1[0], result1[1]))\n",
    "print('[테스트 모델 평가] loss: %.4f, accuracy: %.4f' % (result2[0], result2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set으로 학습 수행\n",
    "df = pd.read_csv('../data/sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "seed=1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "# del: 식별자 제거 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model.evaluate(X_train, Y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load.model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb275202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=1234)\n",
    "\n",
    "result1 = new_model.evaluate(X_train, Y_train, verbose=0)\n",
    "result2 = new_model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('[학습 모델 평가] loss: %.4f, accuracy: %.4f' % (result1[0], result1[1]))\n",
    "print('[테스트 모델 평가] loss: %.4f, accuracy: %.4f' % (result2[0], result2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed57cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반드시 저장 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05591378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 221111 강의\n",
    "\n",
    "# StratifiedKFold - 분류\n",
    "# KFold - 회귀 (3판 오류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82383f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 60) (42, 60) (166,) (42,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:60].astype(np.float64)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)\n",
    "\n",
    "seed=1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=1234)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2b6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1439a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]: [  0   1   2   3   4   6   7   8   9  10  11  12  15  16  17  18  20  21\n",
      "  22  23  24  25  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  45  46  47  48  49  50  51  52  54  55  56  57  59  60  62  63\n",
      "  65  66  67  68  69  70  71  72  74  75  76  77  78  80  81  82  83  84\n",
      "  85  86  87  91  93  95  96  97  98  99 102 104 106 108 109 110 111 112\n",
      " 114 115 116 117 119 122 124 126 128 129 130 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 147 148 149 150 151 152 153 155 156 157 158 159\n",
      " 160 161 162 163 164 165]\n",
      "[test]: [  5  13  14  19  26  43  44  53  58  61  64  73  79  88  89  90  92  94\n",
      " 100 101 103 105 107 113 118 120 121 123 125 127 131 132 146 154]\n",
      "--------------------------------------------------------------\n",
      "[train]: [  0   1   2   3   5   6   8   9  10  11  12  13  14  15  18  19  20  21\n",
      "  22  24  25  26  27  28  31  32  33  34  35  36  37  39  40  42  43  44\n",
      "  45  46  47  48  49  50  52  53  55  58  59  60  61  62  63  64  65  67\n",
      "  69  71  72  73  74  75  76  77  79  80  81  82  83  85  86  87  88  89\n",
      "  90  91  92  94  95  96  98  99 100 101 103 104 105 106 107 108 111 112\n",
      " 113 117 118 119 120 121 122 123 124 125 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 143 144 145 146 147 148 151 153 154 155 157\n",
      " 158 159 160 161 162 164 165]\n",
      "[test]: [  4   7  16  17  23  29  30  38  41  51  54  56  57  66  68  70  78  84\n",
      "  93  97 102 109 110 114 115 116 126 142 149 150 152 156 163]\n",
      "--------------------------------------------------------------\n",
      "[train]: [  0   1   4   5   6   7   8   9  10  11  13  14  15  16  17  18  19  20\n",
      "  21  23  24  25  26  27  29  30  31  34  35  36  37  38  39  40  41  43\n",
      "  44  45  47  48  51  52  53  54  55  56  57  58  59  60  61  63  64  65\n",
      "  66  67  68  70  72  73  74  76  78  79  80  81  82  84  85  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 107 108 109\n",
      " 110 111 113 114 115 116 118 120 121 122 123 125 126 127 128 129 131 132\n",
      " 135 137 138 139 140 141 142 143 144 146 147 149 150 151 152 154 155 156\n",
      " 157 158 159 161 163 164 165]\n",
      "[test]: [  2   3  12  22  28  32  33  42  46  49  50  62  69  71  75  77  83  86\n",
      "  87 106 112 117 119 124 130 133 134 136 145 148 153 160 162]\n",
      "--------------------------------------------------------------\n",
      "[train]: [  0   2   3   4   5   7   8   9  12  13  14  15  16  17  19  22  23  25\n",
      "  26  28  29  30  31  32  33  38  39  41  42  43  44  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  60  61  62  64  66  67  68  69  70  71\n",
      "  72  73  75  77  78  79  80  81  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  97  98 100 101 102 103 105 106 107 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133\n",
      " 134 136 137 138 140 141 142 144 145 146 147 148 149 150 151 152 153 154\n",
      " 156 158 160 161 162 163 164]\n",
      "[test]: [  1   6  10  11  18  20  21  24  27  34  35  36  37  40  45  59  63  65\n",
      "  74  76  82  96  99 104 108 122 135 139 143 155 157 159 165]\n",
      "--------------------------------------------------------------\n",
      "[train]: [  1   2   3   4   5   6   7  10  11  12  13  14  16  17  18  19  20  21\n",
      "  22  23  24  26  27  28  29  30  32  33  34  35  36  37  38  40  41  42\n",
      "  43  44  45  46  49  50  51  53  54  56  57  58  59  61  62  63  64  65\n",
      "  66  68  69  70  71  73  74  75  76  77  78  79  82  83  84  86  87  88\n",
      "  89  90  92  93  94  96  97  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 130\n",
      " 131 132 133 134 135 136 139 142 143 145 146 148 149 150 152 153 154 155\n",
      " 156 157 159 160 162 163 165]\n",
      "[test]: [  0   8   9  15  25  31  39  47  48  52  55  60  67  72  80  81  85  91\n",
      "  95  98 111 128 129 137 138 140 141 144 147 151 158 161 164]\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for train, test in skf.split(X_train, Y_train):\n",
    "    print('[train]:', train)\n",
    "    print('[test]:', test)\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f503393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88d74d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014E1CFDC430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "acc_score = []\n",
    "\n",
    "for train, test in skf.split(X_train, Y_train):\n",
    "    model = model_fn() # 반복할 때마다 새로운 모델 만드는 문제 발생\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train[train], Y_train[train], epochs=200, batch_size=10, verbose=0)\n",
    "    result = model.evaluate(X_train[test], Y_train[test], verbose=0)\n",
    "    acc_score.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17abab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_Fold_test_acc: 0.8440285205841065 test accuracy: 0.8095238208770752\n"
     ]
    }
   ],
   "source": [
    "K_Fold_test_acc = sum(acc_score) / n_fold\n",
    "test_result = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('K_Fold_test_acc:', K_Fold_test_acc, 'test accuracy:', test_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1afae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지 모델은 계속 새로운 모델 만들어서, 이전 모델들이 다 사라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2462ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=60, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "for train, test in skf.split(X_train, Y_train):\n",
    "    model.fit(X_train[train], Y_train[train], epochs=200, batch_size=10, verbose=0)\n",
    "    result = model.evaluate(X_train[test], Y_train[test], verbose=0)\n",
    "    acc_score.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accc9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7352941036224365, 0.9696969985961914, 1.0, 1.0, 1.0]\n",
      "K_Fold_test_acc: 0.9409982204437256 test accuracy: 0.9047619104385376\n"
     ]
    }
   ],
   "source": [
    "print(acc_score)\n",
    "K_Fold_test_acc = sum(acc_score) / n_fold\n",
    "test_result = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('K_Fold_test_acc:', K_Fold_test_acc, 'test accuracy:', test_result[1])\n",
    "\n",
    "# KFold 특성상 테스트셋이 이전에 계속 학습되는 게 누적되어 나중에는 100% 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae989ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
